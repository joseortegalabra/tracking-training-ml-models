{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7156d7d",
   "metadata": {},
   "source": [
    "# Deploy mlflow en un cloud Run\n",
    "\n",
    "### local\n",
    "Mlflow puede funcionar de forma local de forma simple: se crea una carpeta donde se van a almacenar los resultados, luego al correr mlflow se define que dicha carpeta será la conexión con mlflow. Luego, si se desea ver los resultados en una interfaz web basta con que en la consola se corra \"mlflow server\" para correr en un local host el servidor de mlflow\n",
    "\n",
    "\n",
    "### cloud: cluster  + cloud sql\n",
    "Una forma de habilitar mlflow en cloud es tener un cluster kubernetes encendido y una instancia de cloud sql. Esto gasta dinero al estar siempre encendido y es innecesario si se desea utilizar mlflow solo como una herramienta para registrar los resultados de experimentación de modelos\n",
    "\n",
    "\n",
    "### cloud: GCS + cloud run\n",
    "Esta es la solución más sencilla. En local se guardaba los resultados en una carpeta, en cloud se van a guardar en google cloud storage. Luego para mostrar la interfaz web se crea un servicio de cloud run que al abrirlo se muestra la UI de mlflow y solo gasta recursos mientras está abierto. En este notebook se va a mostrar cómo hacer esta implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840672e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "919f18e7",
   "metadata": {},
   "source": [
    "### INFO MLFLOW\n",
    "\n",
    "Documentación cómo son guardados los resultados: https://mlflow.org/docs/latest/tracking.html#how-runs-and-artifacts-are-recorded\n",
    "\n",
    "Al correr el código para crear el servidor:\n",
    "\n",
    "`mlflow server`\n",
    "\n",
    "En resumen, se deben definir 2 variables:\n",
    "- `--backend-store-uri` La que se utiliza para especificar la ubicación del almacenamiento de backend utilizado para almacenar y recuperar los datos de seguimiento de MLflow, como métricas, parámetros, artefactos y registros de ejecución. (Por ejemplo: file:///path/to/mlruns)\n",
    "\n",
    "- `--default-artifact-root` La que debe indicar la ubicación de los artefactos (La data que es más pesada, en comparación con métricas, parámetros, registros de experimentos)\n",
    "\n",
    "\n",
    "Un ejemplo de implementación es:\n",
    "\n",
    "`mlflow server \\\n",
    "    --backend-store-uri /mnt/persistent-disk \\\n",
    "    --default-artifact-root s3://my-mlflow-bucket/ \\\n",
    "    --host 0.0.0.0`\n",
    "\n",
    "\n",
    "\n",
    "Los recursos permitidos son:\n",
    "- `--backend-store-uri`: local // MLflow supports the database dialects mysql, mssql, sqlite, and postgresql\n",
    "\n",
    "- `--default-artifact-root`: local // Servicios de Storage de las diferentes nubes\n",
    "\n",
    "\n",
    "**Consideraciones para implementación cloud**\n",
    "- Se puede crear un servidor de mlflow alojado en un cloud run pero se debe de tener cuidado que si alguna de estas variables se guardan en local, va a ser el local del cloud run y cuando la instancia se desactive, toda la info va a desaparecer\n",
    "\n",
    "- Additionally, you should ensure that the --backend-store-uri (which defaults to the ./mlruns directory) points to a persistent (non-ephemeral) disk or database connection. (Sources: https://mlflow.org/docs/latest/tracking.html#networking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96709a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d562b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f7c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33858364",
   "metadata": {},
   "source": [
    "### 0. Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed8b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generales GCP\n",
    "PROJECT_ID = 'cmpc-innovation-cd4ml-test'\n",
    "REGION = 'us-east1'\n",
    "\n",
    "# bucket para mlflow\n",
    "BUCKET_MLFLOW_CLOUDRUN = 'mlflow_cloudrun'\n",
    "\n",
    "# repo de artifact registry\n",
    "NAME_REPO = 'repo-mlflow-cloudrun-2-2-1'\n",
    "FORMAT_REPO = 'docker'\n",
    "DESCRIPTION_REPO = \"repo para mlflow serverless 2.2.1\"\n",
    "NAME_IMAGE = 'mlflow-cloudrun-2-2-1'\n",
    "\n",
    "# nombre de cloud run\n",
    "NAME_CLOUD_RUN = 'mlflow-cloudrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e5acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c1ce8c7",
   "metadata": {},
   "source": [
    "### 1. Setear proyecto GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db2ca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9632e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f67dc52a",
   "metadata": {},
   "source": [
    "### 2. Crear bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da9b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(project, bucket_name, region):\n",
    "    '''\n",
    "    Crear el bucket en GCS\n",
    "    '''\n",
    "    storage_client = storage.Client(project = project)\n",
    "    bucket = storage_client.create_bucket(bucket_name, location = region)\n",
    "    print(\"Bucket {} created\".format(bucket.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff094cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket mlflow_cloudrun created\n"
     ]
    }
   ],
   "source": [
    "# bucket GCS para mlflow\n",
    "create_bucket(project = PROJECT_ID, \n",
    "              bucket_name = BUCKET_MLFLOW_CLOUDRUN, \n",
    "              region = REGION\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57baf681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2e84236",
   "metadata": {},
   "source": [
    "### 2.B Crear carpetas en GCS\n",
    "- \"mlflow_artifacts\" Para almacenar los artefactos\n",
    "- \"mlflow_backend\" Para almacenar el backend (registros experimentos, métricas, parámetros, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f61920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actualmente lo hago manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4168568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e741e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f367c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6783ecd",
   "metadata": {},
   "source": [
    "### 3. Obtener SA que tenga los permisos para leer y guardar en GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0530f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json con credenciales - service account\n",
    "path_credentials = 'sa-gcp-mlflow.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaef189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d901628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12634d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72112b17",
   "metadata": {},
   "source": [
    "### 4. Crear dockerfile para cloud run\n",
    "\n",
    "En python se puede crear un string que represente al dockerfile (pudiendo modificarse los valores) y luego guardar el archivo\n",
    "\n",
    "---\n",
    "agregar si hubiera un archivo requirements\n",
    "RUN pip install --no-cache-dir -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d29c711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend:  gs://mlflow_cloudrun/mlflow_backend\n",
      "artifacts:  gs://mlflow_cloudrun/mlflow_artifacts\n"
     ]
    }
   ],
   "source": [
    "# definir path folders\n",
    "folder_backend = f\"gs://{BUCKET_MLFLOW_CLOUDRUN}\" + \"/mlflow_backend\"\n",
    "folder_artifacts = f\"gs://{BUCKET_MLFLOW_CLOUDRUN}\" + \"/mlflow_artifacts\"\n",
    "\n",
    "\n",
    "print('backend: ', folder_backend)\n",
    "print('artifacts: ', folder_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca87dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear string que representa al dockerfile - fijando artifacts y backend\n",
    "\n",
    "string_dockerfile = f'''\n",
    "FROM python:3.8-slim-buster\n",
    "\n",
    "# Copiar los archivos del proyecto de MLflow a la imagen de Docker\n",
    "COPY . /app\n",
    "WORKDIR /app\n",
    "\n",
    "# Instala las dependencias necesarias\n",
    "RUN pip install google-cloud-storage mlflow==2.2.1\n",
    "\n",
    "# Copia el archivo de credenciales a la imagen de Docker\n",
    "COPY {path_credentials} /app/{path_credentials}\n",
    "\n",
    "# Establece la variable de entorno GOOGLE_APPLICATION_CREDENTIALS\n",
    "ENV GOOGLE_APPLICATION_CREDENTIALS=/app/{path_credentials}\n",
    "\n",
    "# Establecer el Bucket para la conexión con mlflow\n",
    "ENV MLFLOW_MODEL_REGISTRY_URI = gs://{BUCKET_MLFLOW_CLOUDRUN}\n",
    "\n",
    "# Inicia el servidor de MLflow\n",
    "CMD mlflow server --backend-store-uri {folder_backend} --default-artifact-root {folder_artifacts} --host 0.0.0.0 --port 8080\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b686c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar dockerfile\n",
    "with open('Dockerfile', 'w') as file:\n",
    "    file.write(string_dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7411d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c8422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd6026de",
   "metadata": {},
   "source": [
    "### 5. Crear repo en artifact Registry\n",
    "- Para crear un servicio de cloud se hace a partir de una imagen (dockerfile creado en el paso anterior) y dicha imagen debe ser almacenada en un repo de \"Artifact Registry\"\n",
    "\n",
    "- Se procede a crear el repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "071bbd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "# crear repo\n",
    "! gcloud artifacts repositories create $NAME_REPO \\\n",
    "--repository-format $FORMAT_REPO \\\n",
    "--location $REGION \\\n",
    "--description \"$DESCRIPTION_REPO\" \\\n",
    "--async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57ab15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb63513d",
   "metadata": {},
   "source": [
    "### 6. Configurar una compilación de Docker\n",
    "Es necesario crear un yaml con la configuración para compilar la imagen docker en Artifact Registry\n",
    "\n",
    "-> El siguiente código está parametrizado y no es necesario tocar para ninguna implementación de cloud run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bbb3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear diccionario python con el contenido del yaml cloudbuild genérico\n",
    "dict_python_yaml_cloudbuild = {'steps': [{'name': 'gcr.io/cloud-builders/docker',\n",
    "   'args': ['build', '-t', '${_LOCATION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE}', '.']}],\n",
    " 'images': ['${_LOCATION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE}']}\n",
    "\n",
    "\n",
    "# guardar diccionario en formato yaml\n",
    "with open(r'cloudbuild.yaml', 'w') as file:\n",
    "    documents = yaml.dump(dict_python_yaml_cloudbuild, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3f599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "203b2874",
   "metadata": {},
   "source": [
    "### 7. Contenerizar (imagen docker) utilizando cloud build y subirlas a artifact registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9ac475d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"ada2558f-342e-462f-9652-cb1e41fffd0c\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://cmpc-innovation-cd4ml-test_cloudbuild/source/1678371942.84179-b92353a5e9954d77b90ea2cce6ffa165.tgz#1678371943016923\n",
      "Copying gs://cmpc-innovation-cd4ml-test_cloudbuild/source/1678371942.84179-b92353a5e9954d77b90ea2cce6ffa165.tgz#1678371943016923...\n",
      "/ [0 files][    0.0 B/ 20.5 KiB]                                                \n",
      "/ [1 files][ 20.5 KiB/ 20.5 KiB]                                                \n",
      "\n",
      "Operation completed over 1 objects/20.5 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  92.16kB\n",
      "\n",
      "\n",
      "Step 1/7 : FROM python:3.8-slim-buster\n",
      "3.8-slim-buster: Pulling from library/python\n",
      "8fd419aca81c: Pulling fs layer\n",
      "e53683fb464b: Pulling fs layer\n",
      "92b8eda1d319: Pulling fs layer\n",
      "80cabd6bcbca: Pulling fs layer\n",
      "ae9d18f64c34: Pulling fs layer\n",
      "80cabd6bcbca: Waiting\n",
      "ae9d18f64c34: Waiting\n",
      "e53683fb464b: Verifying Checksum\n",
      "e53683fb464b: Download complete\n",
      "92b8eda1d319: Verifying Checksum\n",
      "92b8eda1d319: Download complete\n",
      "80cabd6bcbca: Verifying Checksum\n",
      "80cabd6bcbca: Download complete\n",
      "ae9d18f64c34: Verifying Checksum\n",
      "ae9d18f64c34: Download complete\n",
      "8fd419aca81c: Verifying Checksum\n",
      "8fd419aca81c: Download complete\n",
      "8fd419aca81c: Pull complete\n",
      "e53683fb464b: Pull complete\n",
      "92b8eda1d319: Pull complete\n",
      "80cabd6bcbca: Pull complete\n",
      "ae9d18f64c34: Pull complete\n",
      "Digest: sha256:f51af6b4116b1c3a5a7934070b0761d1dcb82592ee7e8ecee8ab93d3e2a3cfe2\n",
      "Status: Downloaded newer image for python:3.8-slim-buster\n",
      " ---> 48d520b650a8\n",
      "Step 2/7 : COPY . /app\n",
      " ---> eee855432688\n",
      "Step 3/7 : WORKDIR /app\n",
      " ---> Running in 2dc3b7140fac\n",
      "Removing intermediate container 2dc3b7140fac\n",
      " ---> c9b3f6e06302\n",
      "Step 4/7 : RUN pip install google-cloud-storage mlflow==2.2.1\n",
      " ---> Running in 61c30e703e67\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.7.0-py2.py3-none-any.whl (110 kB)\n",
      "     ??????????????????????????????????????? 110.2/110.2 KB 7.3 MB/s eta 0:00:00\n",
      "Collecting mlflow==2.2.1\n",
      "  Downloading mlflow-2.2.1-py3-none-any.whl (17.6 MB)\n",
      "     ???????????????????????????????????????? 17.6/17.6 MB 35.6 MB/s eta 0:00:00\n",
      "Collecting pyyaml<7,>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "     ?????????????????????????????????????? 701.2/701.2 KB 50.0 MB/s eta 0:00:00\n",
      "Collecting pyarrow<12,>=4.0.0\n",
      "  Downloading pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n",
      "     ???????????????????????????????????????? 35.0/35.0 MB 27.8 MB/s eta 0:00:00\n",
      "Collecting Jinja2<4,>=2.11\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     ?????????????????????????????????????? 133.1/133.1 KB 23.2 MB/s eta 0:00:00\n",
      "Collecting click<9,>=7.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ???????????????????????????????????????? 96.6/96.6 KB 16.9 MB/s eta 0:00:00\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "     ???????????????????????????????????????? 42.8/42.8 KB 7.0 MB/s eta 0:00:00\n",
      "Collecting protobuf<5,>=3.12.0\n",
      "  Downloading protobuf-4.22.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "     ?????????????????????????????????????? 302.4/302.4 KB 34.8 MB/s eta 0:00:00\n",
      "Collecting markdown<4,>=3.3\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ???????????????????????????????????????? 93.3/93.3 KB 16.4 MB/s eta 0:00:00\n",
      "Collecting Flask<3\n",
      "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
      "     ?????????????????????????????????????? 101.8/101.8 KB 17.4 MB/s eta 0:00:00\n",
      "Collecting matplotlib<4\n",
      "  Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "     ???????????????????????????????????????? 9.2/9.2 MB 48.2 MB/s eta 0:00:00\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "     ?????????????????????????????????????? 184.3/184.3 KB 27.2 MB/s eta 0:00:00\n",
      "Collecting packaging<24\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "     ???????????????????????????????????????? 42.7/42.7 KB 7.2 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata!=4.7.0,<7,>=3.7.0\n",
      "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting pytz<2023\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "     ?????????????????????????????????????? 499.4/499.4 KB 47.5 MB/s eta 0:00:00\n",
      "Collecting pandas<3\n",
      "  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "     ???????????????????????????????????????? 12.2/12.2 MB 44.9 MB/s eta 0:00:00\n",
      "Collecting gunicorn<21\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "     ???????????????????????????????????????? 79.5/79.5 KB 13.0 MB/s eta 0:00:00\n",
      "Collecting sqlalchemy<3,>=1.4.0\n",
      "  Downloading SQLAlchemy-2.0.5.post1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "     ???????????????????????????????????????? 2.8/2.8 MB 92.1 MB/s eta 0:00:00\n",
      "Collecting shap<1,>=0.40\n",
      "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
      "     ?????????????????????????????????????? 575.9/575.9 KB 47.9 MB/s eta 0:00:00\n",
      "Collecting docker<7,>=4.0.0\n",
      "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
      "     ?????????????????????????????????????? 147.5/147.5 KB 20.8 MB/s eta 0:00:00\n",
      "Collecting alembic<2\n",
      "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
      "     ?????????????????????????????????????? 212.2/212.2 KB 28.3 MB/s eta 0:00:00\n",
      "Collecting numpy<2\n",
      "  Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "     ???????????????????????????????????????? 17.3/17.3 MB 39.2 MB/s eta 0:00:00\n",
      "Collecting entrypoints<1\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting scikit-learn<2\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "     ???????????????????????????????????????? 9.8/9.8 MB 55.0 MB/s eta 0:00:00\n",
      "Collecting scipy<2\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "     ???????????????????????????????????????? 34.5/34.5 MB 28.8 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2.17.3\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "     ???????????????????????????????????????? 62.8/62.8 KB 11.0 MB/s eta 0:00:00\n",
      "Collecting querystring-parser<2\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Downloading databricks-cli-0.17.4.tar.gz (82 kB)\n",
      "     ???????????????????????????????????????? 82.3/82.3 KB 14.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cloudpickle<3\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
      "     ?????????????????????????????????????? 120.3/120.3 KB 18.5 MB/s eta 0:00:00\n",
      "Collecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "     ?????????????????????????????????????? 177.2/177.2 KB 24.1 MB/s eta 0:00:00\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.4.1-py2.py3-none-any.whl (77 kB)\n",
      "     ???????????????????????????????????????? 77.7/77.7 KB 14.7 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ???????????????????????????????????????? 78.7/78.7 KB 14.2 MB/s eta 0:00:00\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ?????????????????????????????????????? 151.7/151.7 KB 24.1 MB/s eta 0:00:00\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting six>=1.10.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
      "     ???????????????????????????????????????? 55.9/55.9 KB 9.9 MB/s eta 0:00:00\n",
      "Collecting urllib3>=1.26.0\n",
      "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "     ?????????????????????????????????????? 140.6/140.6 KB 21.2 MB/s eta 0:00:00\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "     ?????????????????????????????????????? 233.6/233.6 KB 30.5 MB/s eta 0:00:00\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ???????????????????????????????????????? 62.7/62.7 KB 10.8 MB/s eta 0:00:00\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.58.0-py2.py3-none-any.whl (223 kB)\n",
      "     ?????????????????????????????????????? 223.0/223.0 KB 31.7 MB/s eta 0:00:00\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ?????????????????????????????????????? 155.3/155.3 KB 24.3 MB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.8/site-packages (from gunicorn<21->mlflow==2.2.1) (57.5.0)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting python-dateutil>=2.7\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ?????????????????????????????????????? 247.7/247.7 KB 31.8 MB/s eta 0:00:00\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "     ???????????????????????????????????????? 3.4/3.4 MB 87.5 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.39.0-py3-none-any.whl (1.0 MB)\n",
      "     ???????????????????????????????????????? 1.0/1.0 MB 66.8 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "     ???????????????????????????????????????? 98.3/98.3 KB 15.4 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "     ???????????????????????????????????????? 1.2/1.2 MB 69.6 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "     ?????????????????????????????????????? 300.0/300.0 KB 35.2 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "     ?????????????????????????????????????? 155.3/155.3 KB 22.9 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
      "     ?????????????????????????????????????? 195.9/195.9 KB 27.3 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ???????????????????????????????????????? 61.5/61.5 KB 10.5 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ?????????????????????????????????????? 298.0/298.0 KB 37.4 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting tqdm>4.25.0\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ???????????????????????????????????????? 77.1/77.1 KB 12.2 MB/s eta 0:00:00\n",
      "Collecting numba\n",
      "  Downloading numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "     ???????????????????????????????????????? 3.5/3.5 MB 76.3 MB/s eta 0:00:00\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
      "     ?????????????????????????????????????? 618.5/618.5 KB 48.6 MB/s eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ???????????????????????????????????????? 77.1/77.1 KB 11.9 MB/s eta 0:00:00\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "     ???????????????????????????????????????? 34.6/34.6 MB 23.6 MB/s eta 0:00:00\n",
      "Collecting numpy<2\n",
      "  Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "     ???????????????????????????????????????? 17.1/17.1 MB 41.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: databricks-cli\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142894 sha256=4926fe7de92d8b4be2204a930f9e35cdcafd36621dd69062fed0ae538b0a55b9\n",
      "  Stored in directory: /root/.cache/pip/wheels/48/7c/6e/4bf2c1748c7ecf994ca951591de81674ed6bf633e1e337d873\n",
      "Successfully built databricks-cli\n",
      "Installing collected packages: pytz, pyasn1, zipp, websocket-client, urllib3, typing-extensions, tqdm, threadpoolctl, tabulate, sqlparse, smmap, slicer, six, rsa, pyyaml, pyparsing, pyjwt, pyasn1-modules, protobuf, pillow, packaging, oauthlib, numpy, MarkupSafe, llvmlite, kiwisolver, joblib, itsdangerous, idna, gunicorn, greenlet, google-crc32c, fonttools, entrypoints, cycler, cloudpickle, click, charset-normalizer, certifi, cachetools, Werkzeug, sqlalchemy, scipy, requests, querystring-parser, python-dateutil, pyarrow, Mako, Jinja2, importlib-resources, importlib-metadata, googleapis-common-protos, google-resumable-media, google-auth, gitdb, contourpy, scikit-learn, pandas, numba, matplotlib, markdown, google-api-core, gitpython, Flask, docker, databricks-cli, alembic, shap, google-cloud-core, mlflow, google-cloud-storage\n",
      "Successfully installed Flask-2.2.3 Jinja2-3.1.2 Mako-1.2.4 MarkupSafe-2.1.2 Werkzeug-2.2.3 alembic-1.10.2 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 click-8.1.3 cloudpickle-2.2.1 contourpy-1.0.7 cycler-0.11.0 databricks-cli-0.17.4 docker-6.0.1 entrypoints-0.4 fonttools-4.39.0 gitdb-4.0.10 gitpython-3.1.31 google-api-core-2.11.0 google-auth-2.16.2 google-cloud-core-2.3.2 google-cloud-storage-2.7.0 google-crc32c-1.5.0 google-resumable-media-2.4.1 googleapis-common-protos-1.58.0 greenlet-2.0.2 gunicorn-20.1.0 idna-3.4 importlib-metadata-6.0.0 importlib-resources-5.12.0 itsdangerous-2.1.2 joblib-1.2.0 kiwisolver-1.4.4 llvmlite-0.39.1 markdown-3.4.1 matplotlib-3.7.1 mlflow-2.2.1 numba-0.56.4 numpy-1.23.5 oauthlib-3.2.2 packaging-23.0 pandas-1.5.3 pillow-9.4.0 protobuf-4.22.1 pyarrow-11.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyjwt-2.6.0 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.7.1 pyyaml-6.0 querystring-parser-1.2.4 requests-2.28.2 rsa-4.9 scikit-learn-1.2.2 scipy-1.10.1 shap-0.41.0 six-1.16.0 slicer-0.0.7 smmap-5.0.0 sqlalchemy-2.0.5.post1 sqlparse-0.4.3 tabulate-0.9.0 threadpoolctl-3.1.0 tqdm-4.65.0 typing-extensions-4.5.0 urllib3-1.26.14 websocket-client-1.5.1 zipp-3.15.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 61c30e703e67\n",
      " ---> 0e83ea3dc27e\n",
      "Step 5/7 : COPY cmpc-innovation-cd4ml-test-sa-compute-engine.json /app/cmpc-innovation-cd4ml-test-sa-compute-engine.json\n",
      " ---> 9f8334af8584\n",
      "Step 6/7 : ENV GOOGLE_APPLICATION_CREDENTIALS=/app/cmpc-innovation-cd4ml-test-sa-compute-engine.json\n",
      " ---> Running in 8a2e16c5739c\n",
      "Removing intermediate container 8a2e16c5739c\n",
      " ---> 84b57ddc9801\n",
      "Step 7/7 : CMD mlflow server --backend-store-uri gs://mlflow_cloudrun/mlflow_backend --default-artifact-root gs://mlflow_cloudrun/mlflow_artifacts --host 0.0.0.0 --port 8080\n",
      " ---> Running in 63eccded0a1f\n",
      "Removing intermediate container 63eccded0a1f\n",
      " ---> 98c27e7e6006\n",
      "Successfully built 98c27e7e6006\n",
      "Successfully tagged us-east1-docker.pkg.dev/cmpc-innovation-cd4ml-test/repo-mlflow-cloudrun-2-2-1/mlflow-cloudrun-2-2-1:latest\n",
      "PUSH\n",
      "Pushing us-east1-docker.pkg.dev/cmpc-innovation-cd4ml-test/repo-mlflow-cloudrun-2-2-1/mlflow-cloudrun-2-2-1\n",
      "The push refers to repository [us-east1-docker.pkg.dev/cmpc-innovation-cd4ml-test/repo-mlflow-cloudrun-2-2-1/mlflow-cloudrun-2-2-1]\n",
      "6572307261b2: Preparing\n",
      "43b8bf45139e: Preparing\n",
      "27cf5b45ad4d: Preparing\n",
      "62972c37ae78: Preparing\n",
      "3ce375b55733: Preparing\n",
      "2535be25d316: Preparing\n",
      "be5f95edf25e: Preparing\n",
      "d413d872f329: Preparing\n",
      "be5f95edf25e: Waiting\n",
      "d413d872f329: Waiting\n",
      "2535be25d316: Waiting\n",
      "3ce375b55733: Layer already exists\n",
      "62972c37ae78: Layer already exists\n",
      "2535be25d316: Layer already exists\n",
      "be5f95edf25e: Layer already exists\n",
      "d413d872f329: Layer already exists\n",
      "27cf5b45ad4d: Pushed\n",
      "6572307261b2: Pushed\n",
      "43b8bf45139e: Pushed\n",
      "latest: digest: sha256:fd9333f123022c81444179d9e943894a82f53f8fd23196ee17397499c90d49f4 size: 2000\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                   IMAGES                                                                                                         STATUS\n",
      "ada2558f-342e-462f-9652-cb1e41fffd0c  2023-03-09T14:25:44+00:00  2M13S     gs://cmpc-innovation-cd4ml-test_cloudbuild/source/1678371942.84179-b92353a5e9954d77b90ea2cce6ffa165.tgz  us-east1-docker.pkg.dev/cmpc-innovation-cd4ml-test/repo-mlflow-cloudrun-2-2-1/mlflow-cloudrun-2-2-1 (+1 more)  SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 5 file(s) totalling 85.0 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://cmpc-innovation-cd4ml-test_cloudbuild/source/1678371942.84179-b92353a5e9954d77b90ea2cce6ffa165.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/cmpc-innovation-cd4ml-test/locations/global/builds/ada2558f-342e-462f-9652-cb1e41fffd0c].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/ada2558f-342e-462f-9652-cb1e41fffd0c?project=724348686027].\n"
     ]
    }
   ],
   "source": [
    "! gcloud builds submit \\\n",
    "    --config=cloudbuild.yaml \\\n",
    "    --substitutions=_LOCATION=\"$REGION\",_REPOSITORY=\"$NAME_REPO\",_IMAGE=\"$NAME_IMAGE\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3efaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aaa63e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3621b10a",
   "metadata": {},
   "source": [
    "### 8. Deploy de la imagen del contenedor de artifact registry en cloud run\n",
    "\n",
    "\n",
    "**IMPORTANTE: POR PROBLEMAS DE PERMISOS, EL CLOUD RUN ESTÁ CONFIGURADO PARA QUE CUALQUIERA CON EL LINK PUEDA ACCEDER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90a240bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deploying container to Cloud Run service [mlflow-cloudrun] in project [cmpc-innovation-cd4ml-test] region [us-east1]\n",
      "Deploying...\n",
      "Setting IAM Policy.........................done\n",
      "Creating Revision........................................................................................................................................................................................................................................................................................failed\n",
      "Deployment failed\n",
      "ERROR: (gcloud.run.deploy) The user-provided container failed to start and listen on the port defined provided by the PORT=8080 environment variable. Logs for this revision might contain more information.\n",
      "\n",
      "Logs URL: https://console.cloud.google.com/logs/viewer?project=cmpc-innovation-cd4ml-test&resource=cloud_run_revision/service_name/mlflow-cloudrun/revision_name/mlflow-cloudrun-00012-fos&advancedFilter=resource.type%3D%22cloud_run_revision%22%0Aresource.labels.service_name%3D%22mlflow-cloudrun%22%0Aresource.labels.revision_name%3D%22mlflow-cloudrun-00012-fos%22 \n",
      "For more troubleshooting guidance, see https://cloud.google.com/run/docs/troubleshooting#container-failed-to-start\n"
     ]
    }
   ],
   "source": [
    "! gcloud run deploy $NAME_CLOUD_RUN \\\n",
    "    --image $REGION-docker.pkg.dev/$PROJECT_ID/$NAME_REPO/$NAME_IMAGE \\\n",
    "    --region $REGION \\\n",
    "    --allow-unauthenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e58ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec585910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f721c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4edee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5b6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
