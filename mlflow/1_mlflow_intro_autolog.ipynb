{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b3b6e2-122b-4c2a-9cd4-9281e2df5797",
   "metadata": {},
   "source": [
    "# Intro autolog mlflow\n",
    "\n",
    "Links examples:\n",
    "\n",
    "- sklearn: https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.autolog\n",
    "\n",
    "- tensorflow: https://github.com/mlflow/mlflow/blob/master/examples/keras/train.py\n",
    "\n",
    "- other examples: https://mlflow.org/docs/latest/tutorials-and-examples/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566a2b24-c28c-4a65-b47b-46b5cb762426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mlflow\n",
      "Version: 2.3.0\n",
      "Summary: MLflow: A Platform for ML Development and Productionization\n",
      "Home-page: https://mlflow.org/\n",
      "Author: Databricks\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: d:\\anaconda\\envs\\data-science-python-3-10\\lib\\site-packages\n",
      "Requires: alembic, click, cloudpickle, databricks-cli, docker, entrypoints, Flask, gitpython, importlib-metadata, Jinja2, markdown, matplotlib, numpy, packaging, pandas, protobuf, pyarrow, pytz, pyyaml, querystring-parser, requests, scikit-learn, scipy, sqlalchemy, sqlparse, waitress\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "!pip show mlflow # version mflow used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a3c2a-3a34-4b15-8ed4-9adbc8e13b3b",
   "metadata": {},
   "source": [
    "### 1. Autolog tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0dfc3d6-e694-4c55-8276-d44cd9e23676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/24 19:13:23 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2110848/2110848 [==============================] - 1s 0us/step\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n",
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/24 19:13:25 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '102475bc70a64082ba4a5ee27e8f2845', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 1.4121 - accuracy: 0.6853 - val_loss: 1.0615 - val_accuracy: 0.7697\n",
      "Epoch 2/5\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.7763 - accuracy: 0.8195 - val_loss: 0.8973 - val_accuracy: 0.8009\n",
      "Epoch 3/5\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5568 - accuracy: 0.8661 - val_loss: 0.9080 - val_accuracy: 0.7909\n",
      "Epoch 4/5\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.4109 - accuracy: 0.8961 - val_loss: 0.8747 - val_accuracy: 0.7998\n",
      "Epoch 5/5\n",
      "253/253 [==============================] - 2s 9ms/step - loss: 0.3341 - accuracy: 0.9140 - val_loss: 0.8843 - val_accuracy: 0.8087\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\JORTEGAL\\AppData\\Local\\Temp\\tmpbqq0l3cy\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JORTEGAL\\AppData\\Local\\Temp\\tmpbqq0l3cy\\model\\data\\model\\assets\n",
      "2023/12/24 19:13:48 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"D:\\Anaconda\\envs\\data-science-python-3-10\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 1ms/step - loss: 0.8922 - accuracy: 0.7903\n",
      "Test score: 0.8922085165977478\n",
      "Test accuracy: 0.7902938723564148\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Trains and evaluate a simple MLP\n",
    "on the Reuters newswire topic classification task.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# The following import and function call are the only additions to code required\n",
    "# to automatically log metrics and parameters to MLflow.\n",
    "import mlflow\n",
    "\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "max_words = 1000\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2)\n",
    "\n",
    "print(len(x_train), \"train sequences\")\n",
    "print(len(x_test), \"test sequences\")\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, \"classes\")\n",
    "\n",
    "print(\"Vectorizing sequence data...\")\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode=\"binary\")\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode=\"binary\")\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "print(\"Convert class vector to binary class matrix (for use with categorical_crossentropy)\")\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1\n",
    ")\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0693d-e72b-49e4-bd42-8b3f8919509e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7b92f-a429-4c9d-9cc4-22be23331ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22485b40-f14b-4e9f-a5f8-3ee4fe7aa868",
   "metadata": {},
   "source": [
    "### 2. Autolog sklearn\n",
    "Note: the version of sklearn used is not soported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07710694-d133-4309-8e01-6f1ae2fd2bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/24 19:30:13 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics' has no attribute 'SCORERS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_signature\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#mlflow.sklearn.autolog() # oprueba autolog\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautolog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     12\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m23\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data-science-python-3-10\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\__init__.py:413\u001b[0m, in \u001b[0;36mautologging_integration.<locals>.wrapper.<locals>.autolog\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_mlflow_events_and_warnings_behavior_globally(\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;66;03m# MLflow warnings emitted during autologging setup / enablement are likely\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;66;03m# actionable and relevant to the user, so they should be emitted as normal\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    409\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39mis_silent_mode,\n\u001b[0;32m    410\u001b[0m ):\n\u001b[0;32m    411\u001b[0m     _check_and_log_warning_for_unsupported_package_versions(name)\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _autolog(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data-science-python-3-10\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1224\u001b[0m, in \u001b[0;36mautolog\u001b[1;34m(log_input_examples, log_model_signatures, log_models, disable, exclusive, disable_for_unsupported_versions, silent, max_tuning_runs, log_post_training_metrics, serialization_format, registered_model_name, pos_label)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;129m@autologging_integration\u001b[39m(FLAVOR_NAME)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mautolog\u001b[39m(\n\u001b[0;32m    946\u001b[0m     log_input_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    957\u001b[0m     pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    958\u001b[0m ):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;124;03m    Enables (or disables) and configures autologging for scikit-learn estimators.\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;124;03m                      be logged. If used for regression model, the parameter will be ignored.\u001b[39;00m\n\u001b[0;32m   1223\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1224\u001b[0m     \u001b[43m_autolog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLAVOR_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_input_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_input_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_model_signatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_model_signatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclusive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclusive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_for_unsupported_versions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_for_unsupported_versions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tuning_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tuning_runs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_post_training_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_post_training_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data-science-python-3-10\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1786\u001b[0m, in \u001b[0;36m_autolog\u001b[1;34m(flavor_name, log_input_examples, log_model_signatures, log_models, disable, exclusive, disable_for_unsupported_versions, silent, max_tuning_runs, log_post_training_metrics, serialization_format, pos_label)\u001b[0m\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric_name \u001b[38;5;129;01min\u001b[39;00m _get_metric_name_list():\n\u001b[0;32m   1782\u001b[0m         safe_patch(\n\u001b[0;32m   1783\u001b[0m             flavor_name, sklearn\u001b[38;5;241m.\u001b[39mmetrics, metric_name, patched_metric_api, manage_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m         )\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m scorer \u001b[38;5;129;01min\u001b[39;00m \u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSCORERS\u001b[49m\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   1787\u001b[0m         safe_patch(flavor_name, scorer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_score_func\u001b[39m\u001b[38;5;124m\"\u001b[39m, patched_metric_api, manage_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpatched_fn_with_autolog_disabled\u001b[39m(original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.metrics' has no attribute 'SCORERS'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "#mlflow.sklearn.autolog() # oprueba autolog\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([-2, -1, 0, 1, 2, 1, 10, 12, 23]).reshape(-1, 1)\n",
    "    y = np.array([0, 0, 1, 1, 1, 0, 0,0,0])\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    lr.fit(X, y)\n",
    "    score = lr.score(X, y)\n",
    "    print(f\"Score: {score}\")\n",
    "    #mlflow.log_metric(\"score\", score)\n",
    "    predictions = lr.predict(X)\n",
    "    signature = infer_signature(X, predictions)\n",
    "    mlflow.sklearn.log_model(lr, \"model\", signature=signature)\n",
    "    print(f\"Model saved in run {mlflow.active_run().info.run_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f16f47-7591-4c95-8a42-6d2455b5f09a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
