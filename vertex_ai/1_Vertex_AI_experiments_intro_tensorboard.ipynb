{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398c69f2-89c3-4bcf-a765-cce817e36839",
   "metadata": {},
   "source": [
    "# INTRO VERTEX AI EXPERIMENT - TENSORBOARD\n",
    "Intro how to registry artifacts, metrics, params of training of models (neuronal networks of tensorflow) in vertex tensorboard.\n",
    "How to registry in the tensorboard instance located in GCP Vertex\n",
    "\n",
    "Documentation web page: https://cloud.google.com/vertex-ai/docs/experiments/configure-training-script?hl=es-419\n",
    "\n",
    "Documentation example github - log time series metrics: https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/experiments/vertex_ai_model_experimentation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03531ac6-40cf-4e80-b90a-80ae8263aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow as tf\n",
    "\n",
    "# vertex gcp\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a879d54-4a8a-4a61-b245-4938c654b30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aef70bd-8467-44a7-a61e-5ef8f3f08875",
   "metadata": {},
   "source": [
    "### 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dac9daf-08ed-4dfd-ab52-4cc318cc9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_X, data_y = fetch_california_housing(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705e5b6-c092-4ba4-b0c3-23642031939c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ec55b93-7563-41aa-9465-545c858bdeda",
   "metadata": {},
   "source": [
    "### 2. split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07e20c1-2bba-4bd6-a368-a84eda0108dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size = 0.25, random_state = 0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe4be89-e157-4a12-9c2e-10dda4aef206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling X\n",
    "scaler_x = StandardScaler()\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_valid = scaler_x.transform(X_valid)\n",
    "X_test = scaler_x.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_valid = scaler_y.transform(np.array(y_valid).reshape(-1, 1))\n",
    "y_test = scaler_y.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297e3c79-803f-4c9f-844c-6817b650b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes datasets\n",
      "\n",
      "X_train: (12384, 8)\n",
      "X_valid: (3096, 8)\n",
      "X_test: (5160, 8)\n",
      "\n",
      "y_train: (12384, 1)\n",
      "y_valid: (3096, 1)\n",
      "y_test: (5160, 1)\n"
     ]
    }
   ],
   "source": [
    "# review shape\n",
    "print('shapes datasets')\n",
    "print('\\nX_train:', X_train.shape)\n",
    "print('X_valid:', X_valid.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "\n",
    "print('\\ny_train:', y_train.shape)\n",
    "print('y_valid:', y_valid.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b36b6-7d8f-4245-afcd-afa6e159f036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1746244-9a09-4a0b-bca4-4737648882c9",
   "metadata": {},
   "source": [
    "### 3. Create tensorboard instance and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4279d606-6894-4bc4-8fcf-53f84e09dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensorboard_instance_or_create(experiment_name, experiment_description, project_gcp, location_gcp):\n",
    "    \"\"\"\n",
    "    Search if exist a tensorboard instance and get it. If the instance doesn't exist, create it.\n",
    "    The instance of tensorboard has its name with the idea to have the same name of the experiment of vertex ai that will use this instance\n",
    "    of vertex.\n",
    "\n",
    "    Args\n",
    "        experiment_name (string)\n",
    "        experiment_description (string)\n",
    "        project_gcp (string)\n",
    "        location_gcp (string)\n",
    "\n",
    "    Return\n",
    "        id_experiment_tensorboard (vertex ai tensorboard object)\n",
    "    \"\"\"\n",
    "    \n",
    "    ''' search tensorboard instance. if the list is empty the tensorboard instance doesn't exist and it will created '''\n",
    "    # GET tensorboard instance created FILTERING by display name. return a list of the instance doesn't exist return a empty list\n",
    "    list_tensorboard_vertex = vertex_ai.Tensorboard.list(\n",
    "        filter = f'display_name=\"tensorboard-{experiment_name}\"',\n",
    "        project = project_gcp,\n",
    "        location = location_gcp\n",
    "    )\n",
    "\n",
    "    # if vertex tensorboard instance doesn't exist, create it\n",
    "    if len(list_tensorboard_vertex) == 0:\n",
    "        print('--- creating vertex tensorboard instance ---')\n",
    "        id_tensorboard_vertex = vertex_ai.Tensorboard.create(display_name = f'tensorboard-{experiment_name}',\n",
    "                                                                 description = f'tensorboard-{experiment_description}',\n",
    "                                                                 project = project_gcp,\n",
    "                                                                 location = location_gcp\n",
    "                                                                ) # return tensorboard instance created\n",
    "    else:\n",
    "        print('--- tensorboard instance already exists ---')\n",
    "        id_tensorboard_vertex = list_tensorboard_vertex[0] # tensorboard instance exists, return it\n",
    "    \n",
    "    return id_tensorboard_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87ff1d4-5198-4c62-9dee-905746ee021d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- tensorboard instance already exists ---\n",
      "\n",
      "--- setting experiment vertex ai ---\n"
     ]
    }
   ],
   "source": [
    "\"\"\" PARAMETERS \"\"\"\n",
    "# get environment variables from .env - only necesary using a jupyter notebook\n",
    "load_dotenv(find_dotenv())\n",
    "PROJECT_GCP = os.environ.get(\"PROJECT_GCP\", \"\")\n",
    "LOCATION_GCP = os.environ.get(\"LOCATION_GCP\", \"\")\n",
    "BUCKET_NAME = os.environ.get(\"BUCKET_NAME\", \"\")\n",
    "\n",
    "# PARAMETERS TO CREATE AN EXPERIMENT IN VERTEX AI\n",
    "EXPERIMENT_NAME = 'house-price-tensorflow'\n",
    "EXPERIMENT_DESCRIPTION = 'Test to train tensorflow models and registry it in tensorboard full'\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" RUN \"\"\"\n",
    "# search tensorboard instance, if it doesn't exist -> created it\n",
    "id_tensorboard_vertex = get_tensorboard_instance_or_create(experiment_name = EXPERIMENT_NAME,\n",
    "                                                           experiment_description = EXPERIMENT_DESCRIPTION,\n",
    "                                                           project_gcp = PROJECT_GCP,\n",
    "                                                           location_gcp = LOCATION_GCP\n",
    "                                                          )\n",
    "\n",
    "# set experiment (or created if it doesn't exist - automatically)\n",
    "print('\\n--- setting experiment vertex ai ---')\n",
    "vertex_ai.init(\n",
    "    experiment = EXPERIMENT_NAME,\n",
    "    experiment_description = EXPERIMENT_DESCRIPTION,\n",
    "    experiment_tensorboard = id_tensorboard_vertex,\n",
    "    project = PROJECT_GCP,\n",
    "    location = LOCATION_GCP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95b7857-2271-4078-908c-8a378b1af0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.tensorboard.tensorboard_resource.Tensorboard object at 0x00000180B6F61C00> \n",
       "resource name: projects/724348686027/locations/us-east1/tensorboards/583919839186255872"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_tensorboard_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843a5b3-039b-41c7-8bb4-c4dc9c7fa19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a22e9-146d-4e94-8215-43ccf7aa8ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "649b4096-27d9-494e-8bd7-ed9ac8bd07ae",
   "metadata": {},
   "source": [
    "### 4. Start run in vertex experiment to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81b43574-9a2f-4621-8ce7-707f50b054e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/724348686027/locations/us-east1/metadataStores/default/contexts/house-price-tensorflow-run-6 to Experiment: house-price-tensorflow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.metadata.experiment_run_resource.ExperimentRun at 0x180bccd9420>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" registry run in experiment \"\"\"\n",
    "RUN_NAME = \"run-6\"\n",
    "\n",
    "# create a run\n",
    "vertex_ai.start_run(RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd0f80-5d59-46fe-8f5c-1e4bbe4c20f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90328a-bbff-4989-8f7f-0397207d3224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61098a-de3b-41b7-bfe5-314558fb1e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef86fac1-1157-4f4f-9eee-6505daf38379",
   "metadata": {},
   "source": [
    "### 5. Train model and registry it in run of vertex experiment and tensorboard instance in vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb5c6faf-55a4-41e0-bb29-b285b2f2577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(seq_lengh):\n",
    "        return tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(512, activation=\"relu\", input_shape=(seq_lengh,)),\n",
    "                tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(1, activation=\"relu\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c24d4a61-22d9-4f33-a0c6-6244190a5795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create nn\n",
    "model = create_model(seq_lengh = X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf183b10-91e4-401a-bd92-37d8e60e1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error', \n",
    "              metrics=[\n",
    "                  tf.keras.metrics.MeanSquaredError(name=\"mse\"),\n",
    "                  tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"),\n",
    "                  tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04e0eb5d-3fe4-4de0-85c6-334ae5aad7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 512)               4608      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168961 (660.00 KB)\n",
      "Trainable params: 168961 (660.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e697e041-7956-47e7-bbc8-820fe142f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callback TO SAVE MORE RESULTS IN TENSORBOARD vertex (more results than metrics)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir = f'gs://{id_tensorboard_vertex.gca_resource.blob_storage_path_prefix}',\n",
    "        histogram_freq=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cb38d41-0bc8-459a-af6c-cd860af88bed",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error executing an HTTP request: HTTP response code 400 with body '{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid bucket name: 'cloud-ai-platform-842676af-776b-48aa-8d24-03041c5fafda\\\\train'\",\n    \"errors\": [\n      {\n        \"message\": \"Invalid bucket name: 'cloud-ai-platform-842676af-776b-48aa-8d24-03041c5fafda\\\\train'\",\n        \"domain\": \"global\",\n        \"reason\": \"invalid\"\n      }\n    ]\n  }\n}\n' [Op:CreateSummaryFileWriter] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 16, 32, 64\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data-science-python-3-10\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data-science-python-3-10\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   6655\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6656\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} Error executing an HTTP request: HTTP response code 400 with body '{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid bucket name: 'cloud-ai-platform-842676af-776b-48aa-8d24-03041c5fafda\\\\train'\",\n    \"errors\": [\n      {\n        \"message\": \"Invalid bucket name: 'cloud-ai-platform-842676af-776b-48aa-8d24-03041c5fafda\\\\train'\",\n        \"domain\": \"global\",\n        \"reason\": \"invalid\"\n      }\n    ]\n  }\n}\n' [Op:CreateSummaryFileWriter] name: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=2, \n",
    "                    batch_size=32, # 16, 32, 64\n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    verbose=1,\n",
    "                    #callbacks=[tensorboard_callback],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd55688-a8f9-4bf2-a492-af7b1634afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" save history - tensorboard vertex ai \"\"\"\n",
    "\n",
    "# run for each epoch of training and get the loss and metrics of each epoch and save in tensorboard vertex\n",
    "for i in range(history.params[\"epochs\"]): \n",
    "        vertex_ai.log_time_series_metrics(\n",
    "            dict(\n",
    "                train_loss = history.history[\"loss\"][i],\n",
    "                train_mse = history.history[\"mse\"][i],\n",
    "                train_rmse = history.history[\"rmse\"][i],\n",
    "                train_mae = history.history[\"mae\"][i],\n",
    "\n",
    "                val_loss = history.history[\"val_loss\"][i],\n",
    "                val_mse = history.history[\"val_mse\"][i],\n",
    "                val_rmse = history.history[\"val_rmse\"][i],\n",
    "                val_mae = history.history[\"val_mae\"][i]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafd83c-955a-4812-83dc-bd69bfb8fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" evaluate in test dataset and save metrics \"\"\"\n",
    "\n",
    "# evaluate \n",
    "metrics = model.evaluate(X_test, return_dict=True)\n",
    "\n",
    "# save vertex metric\n",
    "vertex_ai.log_metrics(\n",
    "    dict(\n",
    "        loss = metrics[\"loss\"],\n",
    "        mse = metrics[\"mse\"],\n",
    "        rmse = metrics[\"rmse\"],\n",
    "        mae = metrics[\"mae\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "333f88a0-7215-4236-8010-22c399c9456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### terminar run\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2498676-19d3-4d02-98c0-efc531a82485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b55e7-9d97-4193-9bac-c7d1209f6b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
