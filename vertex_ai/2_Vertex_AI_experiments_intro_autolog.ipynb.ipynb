{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398c69f2-89c3-4bcf-a765-cce817e36839",
   "metadata": {},
   "source": [
    "# INTRO VERTEX AI EXPERIMENT - AUTOLOG\n",
    "Intro how to registry artifacts, metrics, params of training of models using the autolog.\n",
    "\n",
    "Vertex to autolog parametes and metrics use autolog of mlflow\n",
    "\n",
    "\n",
    "Documentation example github (oficial gcp): https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/get_started_with_vertex_experiments_autologging.ipynb\n",
    "\n",
    "Documentation web page: https://cloud.google.com/vertex-ai/docs/experiments/user-journey/uj-autologging?hl=es-419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03531ac6-40cf-4e80-b90a-80ae8263aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow as tf\n",
    "\n",
    "# vertex gcp\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a879d54-4a8a-4a61-b245-4938c654b30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aef70bd-8467-44a7-a61e-5ef8f3f08875",
   "metadata": {},
   "source": [
    "### 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dac9daf-08ed-4dfd-ab52-4cc318cc9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_X, data_y = fetch_california_housing(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705e5b6-c092-4ba4-b0c3-23642031939c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ec55b93-7563-41aa-9465-545c858bdeda",
   "metadata": {},
   "source": [
    "### 2. split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07e20c1-2bba-4bd6-a368-a84eda0108dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size = 0.25, random_state = 0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe4be89-e157-4a12-9c2e-10dda4aef206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling X\n",
    "scaler_x = StandardScaler()\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_valid = scaler_x.transform(X_valid)\n",
    "X_test = scaler_x.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_valid = scaler_y.transform(np.array(y_valid).reshape(-1, 1))\n",
    "y_test = scaler_y.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297e3c79-803f-4c9f-844c-6817b650b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes datasets\n",
      "\n",
      "X_train: (12384, 8)\n",
      "X_valid: (3096, 8)\n",
      "X_test: (5160, 8)\n",
      "\n",
      "y_train: (12384, 1)\n",
      "y_valid: (3096, 1)\n",
      "y_test: (5160, 1)\n"
     ]
    }
   ],
   "source": [
    "# review shape\n",
    "print('shapes datasets')\n",
    "print('\\nX_train:', X_train.shape)\n",
    "print('X_valid:', X_valid.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "\n",
    "print('\\ny_train:', y_train.shape)\n",
    "print('y_valid:', y_valid.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b36b6-7d8f-4245-afcd-afa6e159f036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1746244-9a09-4a0b-bca4-4737648882c9",
   "metadata": {},
   "source": [
    "### 3. Create tensorboard instance and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4279d606-6894-4bc4-8fcf-53f84e09dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensorboard_instance_or_create(experiment_name, experiment_description, project_gcp, location_gcp):\n",
    "    \"\"\"\n",
    "    Search if exist a tensorboard instance and get it. If the instance doesn't exist, create it.\n",
    "    The instance of tensorboard has its name with the idea to have the same name of the experiment of vertex ai that will use this instance\n",
    "    of vertex.\n",
    "\n",
    "    Args\n",
    "        experiment_name (string)\n",
    "        experiment_description (string)\n",
    "        project_gcp (string)\n",
    "        location_gcp (string)\n",
    "\n",
    "    Return\n",
    "        id_experiment_tensorboard (vertex ai tensorboard object)\n",
    "    \"\"\"\n",
    "    \n",
    "    ''' search tensorboard instance. if the list is empty the tensorboard instance doesn't exist and it will created '''\n",
    "    # GET tensorboard instance created FILTERING by display name. return a list of the instance doesn't exist return a empty list\n",
    "    list_tensorboard_vertex = vertex_ai.Tensorboard.list(\n",
    "        filter = f'display_name=\"tensorboard-{experiment_name}\"',\n",
    "        project = project_gcp,\n",
    "        location = location_gcp\n",
    "    )\n",
    "\n",
    "    # if vertex tensorboard instance doesn't exist, create it\n",
    "    if len(list_tensorboard_vertex) == 0:\n",
    "        print('--- creating vertex tensorboard instance ---')\n",
    "        id_tensorboard_vertex = vertex_ai.Tensorboard.create(display_name = f'tensorboard-{experiment_name}',\n",
    "                                                                 description = f'tensorboard-{experiment_description}',\n",
    "                                                                 project = project_gcp,\n",
    "                                                                 location = location_gcp\n",
    "                                                                ) # return tensorboard instance created\n",
    "    else:\n",
    "        print('--- tensorboard instance already exists ---')\n",
    "        id_tensorboard_vertex = list_tensorboard_vertex[0] # tensorboard instance exists, return it\n",
    "    \n",
    "    return id_tensorboard_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87ff1d4-5198-4c62-9dee-905746ee021d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- creating vertex tensorboard instance ---\n",
      "Creating Tensorboard\n",
      "Create Tensorboard backing LRO: projects/724348686027/locations/us-east1/tensorboards/4601130706800738304/operations/5124543596476760064\n",
      "Tensorboard created. Resource name: projects/724348686027/locations/us-east1/tensorboards/4601130706800738304\n",
      "To use this Tensorboard in another session:\n",
      "tb = aiplatform.Tensorboard('projects/724348686027/locations/us-east1/tensorboards/4601130706800738304')\n",
      "\n",
      "--- setting experiment vertex ai ---\n"
     ]
    }
   ],
   "source": [
    "\"\"\" PARAMETERS \"\"\"\n",
    "# get environment variables from .env - only necesary using a jupyter notebook\n",
    "load_dotenv(find_dotenv())\n",
    "PROJECT_GCP = os.environ.get(\"PROJECT_GCP\", \"\")\n",
    "LOCATION_GCP = os.environ.get(\"LOCATION_GCP\", \"\")\n",
    "BUCKET_NAME = os.environ.get(\"BUCKET_NAME\", \"\")\n",
    "\n",
    "# PARAMETERS TO CREATE AN EXPERIMENT IN VERTEX AI\n",
    "EXPERIMENT_NAME = 'house-price-autolog'\n",
    "EXPERIMENT_DESCRIPTION = 'Test to train a models and autolog in vertex'\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" RUN \"\"\"\n",
    "# search tensorboard instance, if it doesn't exist -> created it\n",
    "id_tensorboard_vertex = get_tensorboard_instance_or_create(experiment_name = EXPERIMENT_NAME,\n",
    "                                                           experiment_description = EXPERIMENT_DESCRIPTION,\n",
    "                                                           project_gcp = PROJECT_GCP,\n",
    "                                                           location_gcp = LOCATION_GCP\n",
    "                                                          )\n",
    "\n",
    "# set experiment (or created if it doesn't exist - automatically)\n",
    "print('\\n--- setting experiment vertex ai ---')\n",
    "vertex_ai.init(\n",
    "    experiment = EXPERIMENT_NAME,\n",
    "    experiment_description = EXPERIMENT_DESCRIPTION,\n",
    "    experiment_tensorboard = id_tensorboard_vertex,\n",
    "    project = PROJECT_GCP,\n",
    "    location = LOCATION_GCP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95b7857-2271-4078-908c-8a378b1af0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.tensorboard.tensorboard_resource.Tensorboard object at 0x000002BB604EBF10> \n",
       "resource name: projects/724348686027/locations/us-east1/tensorboards/4601130706800738304"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_tensorboard_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843a5b3-039b-41c7-8bb4-c4dc9c7fa19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a22e9-146d-4e94-8215-43ccf7aa8ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "649b4096-27d9-494e-8bd7-ed9ac8bd07ae",
   "metadata": {},
   "source": [
    "### 4. Start run in vertex experiment to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b43574-9a2f-4621-8ce7-707f50b054e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/724348686027/locations/us-east1/metadataStores/default/contexts/house-price-autolog-run-1 to Experiment: house-price-autolog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.metadata.experiment_run_resource.ExperimentRun at 0x2bb60664c70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" registry run in experiment \"\"\"\n",
    "RUN_NAME = \"run-1\"\n",
    "\n",
    "# create a run\n",
    "vertex_ai.start_run(RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97dd0f80-5d59-46fe-8f5c-1e4bbe4c20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/31 13:07:00 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n",
      "2023/12/31 13:07:00 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of statsmodels. If you encounter errors during autologging, try upgrading / downgrading statsmodels to a supported version, or try upgrading MLflow.\n",
      "2023/12/31 13:07:01 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "#set autolog\n",
    "vertex_ai.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90328a-bbff-4989-8f7f-0397207d3224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61098a-de3b-41b7-bfe5-314558fb1e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef86fac1-1157-4f4f-9eee-6505daf38379",
   "metadata": {},
   "source": [
    "### 5. Train model and registry it in run of vertex experiment and tensorboard instance in vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb5c6faf-55a4-41e0-bb29-b285b2f2577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(seq_lengh):\n",
    "        return tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(512, activation=\"relu\", input_shape=(seq_lengh,)),\n",
    "                tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(1, activation=\"relu\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c24d4a61-22d9-4f33-a0c6-6244190a5795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create nn\n",
    "model = create_model(seq_lengh = X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf183b10-91e4-401a-bd92-37d8e60e1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error', \n",
    "              metrics=[\n",
    "                  tf.keras.metrics.MeanSquaredError(name=\"mse\"),\n",
    "                  tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"),\n",
    "                  tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04e0eb5d-3fe4-4de0-85c6-334ae5aad7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               4608      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168961 (660.00 KB)\n",
      "Trainable params: 168961 (660.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cb38d41-0bc8-459a-af6c-cd860af88bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/387 [..............................] - ETA: 4:06 - loss: 0.8968 - mse: 0.8968 - rmse: 0.9470 - mae: 0.7899WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.\n",
      "387/387 [==============================] - 2s 5ms/step - loss: 1.0001 - mse: 1.0001 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 2/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 3/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 4/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 5/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 6/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 7/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 8/20\n",
      "387/387 [==============================] - 10s 26ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 9/20\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 10/20\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 11/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 12/20\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 13/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 14/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 15/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 16/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 17/20\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 18/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 19/20\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n",
      "Epoch 20/20\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.0000 - mse: 1.0000 - rmse: 1.0000 - mae: 0.7897 - val_loss: 0.9718 - val_mse: 0.9718 - val_rmse: 0.9858 - val_mae: 0.7816\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=20, \n",
    "                    batch_size=32, # 16, 32, 64\n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "333f88a0-7215-4236-8010-22c399c9456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### terminar run\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2498676-19d3-4d02-98c0-efc531a82485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcc6419c-8a91-486b-acd3-48100d07146f",
   "metadata": {},
   "source": [
    "### You can see in the results, it is not perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3264b50-ebba-400e-b81d-33e5d5b513fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
